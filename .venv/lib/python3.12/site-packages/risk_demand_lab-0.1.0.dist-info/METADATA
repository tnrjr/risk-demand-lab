Metadata-Version: 2.4
Name: risk-demand-lab
Version: 0.1.0
Summary: Semana 1 — Fundação do portfólio ML Jr (repo, linting, tests, API, MLflow, GE)
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: fastapi
Requires-Dist: uvicorn[standard]
Requires-Dist: pandas
Requires-Dist: numpy
Requires-Dist: scikit-learn
Requires-Dist: mlflow
Requires-Dist: great_expectations
Requires-Dist: python-dotenv
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: ruff; extra == "dev"
Requires-Dist: pre-commit; extra == "dev"
Requires-Dist: httpx; extra == "dev"


# Semana 1 — Fundação

> Base pronta para começar o portfólio: ambiente, qualidade de código, API, MLflow e validação de dados.

## Sumário
- **Ambiente**: `pyproject.toml` com deps, `pre-commit` (ruff+black), `pytest`.
- **Makefile**: `make venv`, `make test`, `make train`, `make api`, `make mlflow`, `make up/down` (docker compose).
- **MLflow**: local (file:./mlruns) ou via docker-compose (UI em :5000).
- **Great Expectations**: checagem simples de schema via `schemas/*.yaml`.
- **API**: FastAPI com `/health` e `/predict/credit` (demo).

## 1) Criar e ativar o ambiente
```bash
make venv
source .venv/bin/activate
```

## 2) Pre-commit
Com o venv ativo, os hooks já ficam instalados. Para rodar manualmente:
```bash
pre-commit run --all-files
```

## 3) Testes
```bash
make test
```

## 4) Treino demo + MLflow
Local (file store):
```bash
make train
make mlflow  # UI em http://127.0.0.1:5000
```

Via docker (MLflow + API):
```bash
make up
# MLflow UI: http://127.0.0.1:5000
# API:       http://127.0.0.1:8000/health
```

## 5) API
Local:
```bash
make api  # http://127.0.0.1:8000/health
```

Exemplo de request (credit demo):
```bash
curl -X POST http://127.0.0.1:8000/predict/credit   -H "Content-Type: application/json"   -d '{"feature_1": 0.1, "feature_2": -0.3, "feature_3": 1.2}'
```

## 6) Great Expectations (schema básico)
Edite `schemas/precificacao.yaml` com as colunas verdadeiras do seu CSV.
Depois rode:
```bash
python -m src.validation.ge_validate --dataset precificacao --path data/Precificacao/sample_submission.csv
# Relatório JSON em reports/validation/precificacao_validation.json
```

---

### Notas
- A etapa de treino usa dados **sintéticos**, só para destravar a fundação.
  Troque por seu dataset real assim que quiser, e ajuste os campos do `CreditRequest` na API.
- `docker-compose.yml` sobe o MLflow com SQLite local e artifacts em `./mlruns` (volume mapeado).
- Para parar os serviços docker: `make down`.
